# LLM Service Configuration
PORT=3007
NODE_ENV=development

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_MAX_TOKENS=2000
OPENAI_TEMPERATURE=0.7

# Redis Cache
REDIS_URL=redis://localhost:6379
CACHE_TTL=3600

# Rate Limiting
MAX_REQUESTS_PER_MINUTE=60

# CORS
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001

# Logging
LOG_LEVEL=info